{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2522d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Image, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fec896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardset vars\n",
    "dataset_path = \"data/processed/labeled_asset_dataset_enriched.csv\"\n",
    "config_path = \"config/generation_params.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72038890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for analysis, if it is not present, trigger a mlflow run using the default pipeline settings\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"✅ Dataset loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ {dataset_path} not found. Running MLflow pipeline to generate data...\")\n",
    "    result = subprocess.run(\n",
    "        [\"mlflow\", \"run\", \".\", \"-e\", \"pipeline\", \"--env-manager=local\"],\n",
    "        capture_output=True, text=True, encoding=\"utf-8\", errors=\"replace\"\n",
    "    )\n",
    "    # Print the output, but ignore decode errors and replace weird chars\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(\"❌ MLflow pipeline failed to run. Check the error above.\")\n",
    "        raise RuntimeError(\"MLflow pipeline execution failed\")\n",
    "    if os.path.exists(dataset_path):\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        print(\"✅ Dataset generated and loaded.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Dataset still not found at {dataset_path} after running pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate presence rates\n",
    "total_assets = len(df)\n",
    "present_inventory = (df[\"missing_in_inventory\"] == 0).sum()\n",
    "present_ipam = (df[\"missing_in_ipam\"] == 0).sum()\n",
    "present_all = ((df[\"missing_in_inventory\"] == 0) & (df[\"missing_in_ipam\"] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f668b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentages\n",
    "pct_inventory = present_inventory / total_assets * 100\n",
    "pct_ipam = present_ipam / total_assets * 100\n",
    "pct_all = present_all / total_assets * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print high level stats of presence per system dataset\n",
    "print(f\"Total Observability Assets: {total_assets:,}\")\n",
    "print(f\"Present in Inventory: {present_inventory:,} ({pct_inventory:.1f}%)\")\n",
    "print(f\"Present in IPAM: {present_ipam:,} ({pct_ipam:.1f}%)\")\n",
    "print(f\"Present in BOTH Inventory and IPAM: {present_all:,} ({pct_all:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print table form level stats of presence per system dataset\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Present in Inventory\", \"Present in IPAM\", \"Present in BOTH\"],\n",
    "    \"Count\": [present_inventory, present_ipam, present_all],\n",
    "    \"Percent\": [pct_inventory, pct_ipam, pct_all]\n",
    "})\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the contents of the generation paramaters to display what failure rates were set at data generation\n",
    "with open(config_path, \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Pretty-print as Markdown for notebook display\n",
    "display(Markdown(f\"### Contents of `{config_path}`:\"))\n",
    "display(Markdown(f\"```json\\n{json.dumps(params, indent=4)}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all images in the reports directory (including subdirectories)\n",
    "reports_dir = \"reports\"\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.gif')\n",
    "\n",
    "found_images = []\n",
    "for root, dirs, files in os.walk(reports_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(image_extensions):\n",
    "            found_images.append(os.path.join(root, file))\n",
    "\n",
    "if found_images:\n",
    "    display(Markdown(\"### Generated Report Images\"))\n",
    "    for img_path in found_images:\n",
    "        rel_path = os.path.relpath(img_path, reports_dir)\n",
    "        display(Markdown(f\"**{rel_path}**\"))\n",
    "        display(Image(filename=img_path))\n",
    "else:\n",
    "    print(f\"No report images found in '{reports_dir}' or its subdirectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d751d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
